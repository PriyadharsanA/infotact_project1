{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e70acc-2549-4470-86dc-58aa6e1c97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guys lets do this\n"
     ]
    }
   ],
   "source": [
    "print(\"Guys lets do this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be44d2c9-a537-48f7-acd5-187fca345db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "my_variable = {'user_id': 1, 'top_k': 5}\n",
    "with open('shared_data.pkl', 'wb') as f:\n",
    "    pickle.dump(my_variable, f)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8073c9-6bc3-4994-aa7a-7a52cf33a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bfe084-add9-45e2-9b98-10473113d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3706 entries, 0 to 3705\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   movie_id      3706 non-null   int64 \n",
      " 1   movie_title   3706 non-null   object\n",
      " 2   movie_genres  3706 non-null   object\n",
      " 3   poster_url    3648 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 115.9+ KB\n",
      "Movies:\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   user_id      1000209 non-null  int64  \n",
      " 1   movie_id     1000209 non-null  int64  \n",
      " 2   user_rating  1000209 non-null  float64\n",
      " 3   timestamp    1000209 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 30.5 MB\n",
      "\n",
      "Ratings:\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6040 entries, 0 to 6039\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   user_id                6040 non-null   int64  \n",
      " 1   user_gender            6040 non-null   bool   \n",
      " 2   bucketized_user_age    6040 non-null   float64\n",
      " 3   user_occupation_label  6040 non-null   int64  \n",
      " 4   user_occupation_text   6040 non-null   object \n",
      " 5   user_zip_code          6040 non-null   object \n",
      "dtypes: bool(1), float64(1), int64(2), object(2)\n",
      "memory usage: 242.0+ KB\n",
      "\n",
      "Users:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "movies=pd.read_csv('movies.csv')\n",
    "ratings_chunks = pd.read_csv('ratings.csv', chunksize=100000)\n",
    "ratings = pd.concat(ratings_chunks)\n",
    "users=pd.read_csv('users.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(\"Movies:\\n\",movies.info())\n",
    "print(\"\\nRatings:\\n\",ratings.info())\n",
    "print(\"\\nUsers:\\n\",users.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28dfcc4e-3a51-4c56-ad79-9fa501b94545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\RGUKTS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Drop duplicates and missing values\n",
    "movies.drop_duplicates(inplace=True)\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "# Split genres into lists\n",
    "movies['movie_genres'] = movies['movie_genres'].apply(lambda x: x.split('|'))\n",
    "\n",
    "# One-hot encode genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_encoded = pd.DataFrame(mlb.fit_transform(movies['movie_genres']), columns=mlb.classes_)\n",
    "movies = pd.concat([movies.drop('movie_genres', axis=1), genres_encoded], axis=1)\n",
    "movies['movie_title'] = movies['movie_title'].astype(str)\n",
    "# Clean and tokenize movie_movie_titles\n",
    "def clean_movie_movie_title(movie_movie_title):\n",
    "    return re.sub(r'\\(\\d{4}\\)', '', movie_movie_title).strip()\n",
    "\n",
    "movies['clean_movie_title']=movies['movie_title'].apply(clean_movie_movie_title)\n",
    "movies['movie_title_tokens']=movies['clean_movie_title'].apply(word_tokenize)\n",
    "movies['movie_title_token_count']=movies['movie_title_tokens'].apply(len)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c1eb08-7047-4bf3-aac2-d37424fc4989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    998539.000000\n",
      "mean          3.582575\n",
      "std           1.116516\n",
      "min           1.000000\n",
      "25%           3.000000\n",
      "50%           4.000000\n",
      "75%           4.000000\n",
      "max           5.000000\n",
      "Name: user_rating, dtype: float64\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates and missing values\n",
    "ratings.drop_duplicates(inplace=True)\n",
    "ratings.dropna(inplace=True)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "\n",
    "# Extract date features\n",
    "ratings['year'] = ratings['timestamp'].dt.year\n",
    "ratings['month'] = ratings['timestamp'].dt.month\n",
    "ratings['day'] = ratings['timestamp'].dt.day\n",
    "\n",
    "# Filter users and movies with too few ratings\n",
    "user_counts = ratings['user_id'].value_counts()\n",
    "movie_counts = ratings['movie_id'].value_counts()\n",
    "\n",
    "ratings = ratings[\n",
    "    ratings['user_id'].isin(user_counts[user_counts >= 10].index) &\n",
    "    ratings['movie_id'].isin(movie_counts[movie_counts >= 10].index)\n",
    "]\n",
    "\n",
    "print(ratings['user_rating'].describe())\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb21ad04-7118-4986-9b93-aaa6bf914c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates and missing values\n",
    "users.drop_duplicates(inplace=True)\n",
    "users.dropna(inplace=True)\n",
    "\n",
    "# Convert to categorical\n",
    "users['gender'] = users['user_gender'].astype('category')\n",
    "users['occupation'] = users['user_occupation_label'].astype('category')\n",
    "\n",
    "# Encode gender and occupation\n",
    "users['gender_encoded'] = LabelEncoder().fit_transform(users['gender'])\n",
    "users['occupation_encoded'] = LabelEncoder().fit_transform(users['occupation'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36938608-ac29-4b48-b7fd-e85ba1dbea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Basic Dataset Information ===\n",
      "--------------------------------------------------\n",
      "Number of movies: 3701\n",
      "Number of ratings: 998539\n",
      "Number of users: 6040\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "print(\"\\n=== Basic Dataset Information ===\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of movies: {len(movies)}\")\n",
    "print(f\"Number of ratings: {len(ratings)}\")\n",
    "print(f\"Number of users: {len(users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84632af5-b3ca-4aa0-ab71-51c3bf5e229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out rare genres (e.g., with less than 20 movies)\n",
    "filtered_genre_counts = genre_counts[genre_counts > 20]\n",
    "\n",
    "# Sort genres again (optional)\n",
    "filtered_genre_counts = filtered_genre_counts.sort_values(ascending=True)\n",
    "\n",
    "# Set a clean style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=filtered_genre_counts.values, y=filtered_genre_counts.index)\n",
    "\n",
    "plt.movie_movie_title('Top Genres by Number of Movies', fontsize=14)\n",
    "plt.xlabel('Number of Movies', fontsize=12)\n",
    "plt.ylabel('Genre', fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('clean_genre_distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da205a4d-f04d-4f78-aa85-385043b88ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ✅ RATINGS ANALYSIS\n",
    "# ==========================\n",
    "print(\"\\n=== Ratings Analysis ===\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Distribution of ratings\n",
    "print(\"Creating ratings distribution plot...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=ratings, x='user_rating', bins=20)\n",
    "plt.movie_movie_title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('ratings_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Average rating per movie\n",
    "print(\"Calculating average ratings per movie...\")\n",
    "movie_ratings = ratings.groupby('movie_id')['user_rating'].agg(['mean', 'count']).reset_index()\n",
    "movie_ratings = movie_ratings.merge(movies[['movie_id', 'movie_movie_movie_title']], on='movie_id', how='left')\n",
    "\n",
    "print(\"\\nTop 10 Highest Rated Movies (with at least 100 ratings):\")\n",
    "print(movie_ratings[movie_ratings['count'] >= 100].sort_values('mean', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fa77e-2bbb-4abf-824b-5ad5ce508ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ✅ USER BEHAVIOR ANALYSIS\n",
    "# ==========================\n",
    "print(\"\\n=== User Behavior Analysis ===\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Number of ratings per user\n",
    "print(\"Analyzing user rating patterns...\")\n",
    "user_ratings = ratings.groupby('user_id').size().reset_index(name='rating_count')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=user_ratings, x='rating_count', bins=50)\n",
    "plt.movie_movie_title('Distribution of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.savefig('user_ratings_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nUser Rating Statistics:\")\n",
    "print(user_ratings['rating_count'].describe())\n",
    "\n",
    "# ==========================\n",
    "# ✅ EXPORT ANALYSIS FILES\n",
    "# ==========================\n",
    "print(\"\\nSaving analysis results...\")\n",
    "movie_ratings.to_csv('movie_ratings_analysis.csv', index=False)\n",
    "user_ratings.to_csv('user_ratings_analysis.csv', index=False)\n",
    "genre_df.to_csv('genre_analysis.csv', index=False)\n",
    "\n",
    "print(\"\\nAnalysis complete! Check the generated files:\")\n",
    "print(\"1. infotact_project1/genre_distribution.png\")\n",
    "print(\"2. infotact_project1/ratings_distribution.png\")\n",
    "print(\"3. infotact_project1/user_ratings_distribution.png\")\n",
    "print(\"4. infotact_project1/movie_ratings_analysis.csv\")\n",
    "print(\"5. infotact_project1/user_ratings_analysis.csv\")\n",
    "print(\"6. infotact_project1/genre_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab0fcc5-92cc-47a4-92de-a921fcac3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  user_rating           timestamp  year  month  day  \\\n",
      "0      130      3107          5.0 2000-12-21 20:56:33  2000     12   21   \n",
      "1     3829      2114          4.0 2000-08-10 18:42:47  2000      8   10   \n",
      "2     1265       256          1.0 2002-01-27 03:52:32  2002      1   27   \n",
      "3     2896      1389          5.0 2000-10-20 01:16:45  2000     10   20   \n",
      "4     5264      3635          4.0 2000-06-16 18:28:31  2000      6   16   \n",
      "\n",
      "   user_gender  bucketized_user_age  user_occupation_label  ... 9, 10 9, 13  \\\n",
      "0         True                 35.0                     18  ...   0.0   0.0   \n",
      "1        False                 25.0                      0  ...   0.0   0.0   \n",
      "2        False                 18.0                     21  ...   0.0   0.0   \n",
      "3         True                 18.0                     14  ...   0.0   0.0   \n",
      "4         True                 18.0                     17  ...   0.0   0.0   \n",
      "\n",
      "  9, 13, 16 9, 14, 16  9, 15  9, 15, 16 9, 16      clean_movie_title  \\\n",
      "0       0.0       0.0    0.0        0.0   0.0              Backdraft   \n",
      "1       0.0       0.0    0.0        0.0   0.0         Outsiders, The   \n",
      "2       0.0       0.0    0.0        0.0   0.0                 Junior   \n",
      "3       0.0       0.0    0.0        0.0   0.0               Jaws 3-D   \n",
      "4       0.0       0.0    0.0        0.0   0.0  Spy Who Loved Me, The   \n",
      "\n",
      "              movie_title_tokens  movie_title_token_count  \n",
      "0                    [Backdraft]                        1  \n",
      "1            [Outsiders, ,, The]                        3  \n",
      "2                       [Junior]                        1  \n",
      "3                    [Jaws, 3-D]                        2  \n",
      "4  [Spy, Who, Loved, Me, ,, The]                        6  \n",
      "\n",
      "[5 rows x 321 columns]\n"
     ]
    }
   ],
   "source": [
    "df=ratings.merge(users, on='user_id').merge(movies, on='movie_id')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de5d2fc6-52fe-47d2-8f37-7cd7c972a231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 1:\n",
      "   movie_id                 movie_title\n",
      "0    2081.0  Little Mermaid, The (1989)\n",
      "1    2078.0     Jungle Book, The (1967)\n",
      "2    2096.0      Sleeping Beauty (1959)\n",
      "3     364.0       Lion King, The (1994)\n",
      "4    1282.0             Fantasia (1940)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Pivot to create user-item matrix\n",
    "user_item = ratings.pivot_table(index='user_id', columns='movie_id', values='user_rating')\n",
    "user_item = user_item.fillna(0)\n",
    "\n",
    "# Compute cosine similarity between users\n",
    "user_sim = cosine_similarity(user_item)\n",
    "user_sim_df = pd.DataFrame(user_sim, index=user_item.index, columns=user_item.index)\n",
    "\n",
    "# Predict ratings for a user based on similar users\n",
    "def predict_ratings(target_user_id, user_item, user_sim_df, k=5):\n",
    "    sim_scores = user_sim_df[target_user_id].drop(target_user_id)\n",
    "    top_k_users = sim_scores.nlargest(k).index\n",
    "    sim_subset = sim_scores[top_k_users]\n",
    "    neighbor_ratings = user_item.loc[top_k_users]\n",
    "    weighted_sum = (neighbor_ratings.mul(sim_subset, axis=0)).sum(axis=0)\n",
    "    sim_sum = sim_subset.sum()\n",
    "    predicted_ratings = weighted_sum / sim_sum\n",
    "    return predicted_ratings\n",
    "\n",
    "# Recommend top N movies that the user hasn't rated\n",
    "def recommend_movies(target_user_id, user_item, user_sim_df, movies_df, k=5, n_recs=10):\n",
    "    predicted = predict_ratings(target_user_id, user_item, user_sim_df, k)\n",
    "    already_rated = user_item.loc[target_user_id] > 0\n",
    "    predicted = predicted[~already_rated]\n",
    "    top_movies = predicted.nlargest(n_recs).index\n",
    "    recommendations = movies_df[movies_df['movie_id'].isin(top_movies)][['movie_id', 'movie_title']]\n",
    "    recommendations = recommendations.set_index('movie_id').loc[top_movies].reset_index()\n",
    "    return recommendations\n",
    "\n",
    "# Example: Get top 5 recommendations for user ID 1\n",
    "user_id = 1\n",
    "recommendations = recommend_movies(user_id, user_item, user_sim_df, movies, k=10, n_recs=5)\n",
    "\n",
    "print(f\"Top 5 movie recommendations for User {user_id}:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8af5e24f-b709-444c-8746-ab9955458c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movie recommendations for User 1 (Item-Based):\n",
      "    index                                        movie_title\n",
      "0  2913.0  Mating Habits of the Earthbound Human, The (1998)\n",
      "1   860.0        Maybe, Maybe Not (Bewegte Mann, Der) (1994)\n",
      "2  3058.0                                    Ape, The (1940)\n",
      "3  2636.0                          Mummy's Ghost, The (1944)\n",
      "4  3372.0                      Bridge at Remagen, The (1969)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Pivot to create item-user matrix (transpose of user-item)\n",
    "item_user = ratings.pivot_table(index='movie_id', columns='user_id', values='user_rating')\n",
    "item_user = item_user.fillna(0)\n",
    "\n",
    "# Compute cosine similarity between items (movies)\n",
    "item_sim = cosine_similarity(item_user)\n",
    "item_sim_df = pd.DataFrame(item_sim, index=item_user.index, columns=item_user.index)\n",
    "\n",
    "# Predict ratings for a user based on similar items\n",
    "def predict_item_based_ratings(target_user_id, item_user, item_sim_df):\n",
    "    user_ratings = item_user.loc[:, target_user_id]\n",
    "    rated_items = user_ratings[user_ratings > 0].index\n",
    "\n",
    "    predictions = {}\n",
    "    for item in item_user.index:\n",
    "        if user_ratings[item] == 0:\n",
    "            sim_items = item_sim_df.loc[item, rated_items]\n",
    "            sim_scores = sim_items.values\n",
    "            ratings = user_ratings[rated_items].values\n",
    "            if sim_scores.sum() != 0:\n",
    "                predicted_rating = np.dot(sim_scores, ratings) / sim_scores.sum()\n",
    "                predictions[item] = predicted_rating\n",
    "\n",
    "    return pd.Series(predictions).sort_values(ascending=False)\n",
    "\n",
    "# Recommend top N movies that the user hasn't rated\n",
    "def recommend_movies_item_based(target_user_id, item_user, item_sim_df, movies_df, n_recs=10):\n",
    "    predicted_ratings = predict_item_based_ratings(target_user_id, item_user, item_sim_df)\n",
    "    top_items = predicted_ratings.head(n_recs).index\n",
    "    recommendations = movies_df[movies_df['movie_id'].isin(top_items)][['movie_id', 'movie_title']]\n",
    "    recommendations = recommendations.set_index('movie_id').loc[top_items].reset_index()\n",
    "    return recommendations\n",
    "\n",
    "# Example: Get top 5 recommendations for user ID 1\n",
    "user_id = 1\n",
    "recommendations = recommend_movies_item_based(user_id, item_user, item_sim_df, movies, n_recs=5)\n",
    "\n",
    "print(f\"Top 5 movie recommendations for User {user_id} (Item-Based):\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03347c7a-6579-411c-ab36-c3d68a0b05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a new DataFrame for train/test split\n",
    "ratings_data = ratings[['user_id', 'movie_id', 'user_rating']]\n",
    "\n",
    "# Train-test split by rating records\n",
    "train_data, test_data = train_test_split(ratings_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55975305-f82c-4ec1-985f-6c5ea9bf75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations using SVD:\n",
      "     movie_id                       movie_title\n",
      "117     318.0  Shawshank Redemption, The (1994)\n",
      "175    2081.0        Little Mermaid, The (1989)\n",
      "346      34.0                       Babe (1995)\n",
      "576     364.0             Lion King, The (1994)\n",
      "957    1282.0                   Fantasia (1940)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "# Fill missing ratings with 0s for simplicity (alternatively, you can try mean-centering)\n",
    "train_matrix = train_data.pivot(index='user_id', columns='movie_id', values='user_rating').fillna(0)\n",
    "user_item_matrix = ratings.pivot_table(index='user_id', columns='movie_id', values='user_rating').fillna(0)\n",
    "\n",
    "# Define number of latent features\n",
    "n_components = 50  # You can tune this\n",
    "# SVD: user_item_matrix ≈ U * Sigma * V^T\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "user_features_svd = svd.fit_transform(user_item_matrix)\n",
    "item_features_svd = svd.components_\n",
    "\n",
    "# Reconstruct the ratings matrix\n",
    "predicted_ratings_svd = np.dot(user_features_svd, item_features_svd)\n",
    "\n",
    "# Convert to DataFrame for easy interpretation\n",
    "predicted_svd_df = pd.DataFrame(predicted_ratings_svd, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Example: Get Top 5 recommendations for user 1\n",
    "def recommend_svd(user_id, predicted_df, movies_df, n_recs=5):\n",
    "    user_row = predicted_df.loc[user_id]\n",
    "    rated_movies = user_item_matrix.loc[user_id] > 0\n",
    "    user_row = user_row[~rated_movies]\n",
    "    top_movie_ids = user_row.nlargest(n_recs).index\n",
    "    return movies_df[movies_df['movie_id'].isin(top_movie_ids)][['movie_id', 'movie_title']]\n",
    "\n",
    "print(\"\\nTop 5 Recommendations using SVD:\")\n",
    "print(recommend_svd(1, predicted_svd_df, movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be785af9-cf09-485e-b71a-813bcb06db1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Recommendations using NMF:\n",
      "     movie_id                                        movie_title\n",
      "154    2571.0                                 Matrix, The (1999)\n",
      "215    2858.0                             American Beauty (1999)\n",
      "257     593.0                   Silence of the Lambs, The (1991)\n",
      "331    1198.0                     Raiders of the Lost Ark (1981)\n",
      "859    1196.0  Star Wars: Episode V - The Empire Strikes Back...\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=1, init='random', random_state=42)\n",
    "user_features_nmf = nmf.fit_transform(user_item_matrix)\n",
    "item_features_nmf = nmf.components_\n",
    "\n",
    "# Reconstruct the ratings\n",
    "predicted_ratings_nmf = np.dot(user_features_nmf, item_features_nmf)\n",
    "\n",
    "# Convert to DataFrame\n",
    "predicted_nmf_df = pd.DataFrame(predicted_ratings_nmf, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Example: Get Top 5 recommendations for user 1\n",
    "def recommend_nmf(user_id, predicted_df, movies_df, n_recs=5):\n",
    "    user_row = predicted_df.loc[user_id]\n",
    "    rated_movies = user_item_matrix.loc[user_id] > 0\n",
    "    user_row = user_row[~rated_movies]\n",
    "    top_movie_ids = user_row.nlargest(n_recs).index\n",
    "    return movies_df[movies_df['movie_id'].isin(top_movie_ids)][['movie_id', 'movie_title']]\n",
    "\n",
    "print(\"\\nTop 5 Recommendations using NMF:\")\n",
    "print(recommend_nmf(1, predicted_nmf_df, movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db54deef-d842-4976-b4d9-4753d2fad5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE: 2.2345\n",
      "SVD MAE : 1.9075\n",
      "NMF RMSE: 2.9457\n",
      "NMF MAE : 2.6849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_rmse_mae(test_data, pred_df, name=\"Model\"):\n",
    "    y_true, y_pred = [], []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user, movie, rating = row['user_id'], row['movie_id'], row['user_rating']\n",
    "        if user in pred_df.index and movie in pred_df.columns:\n",
    "            y_true.append(rating)\n",
    "            y_pred.append(pred_df.loc[user, movie])\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"{name} RMSE: {rmse:.4f}\")\n",
    "    print(f\"{name} MAE : {mae:.4f}\")\n",
    "\n",
    "evaluate_rmse_mae(test_data, predicted_svd_df, \"SVD\")\n",
    "evaluate_rmse_mae(test_data, predicted_nmf_df, \"NMF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cba244a-1e09-4f76-9a99-d41835c3572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Precision@10: 0.4143\n",
      "NMF Precision@10: 0.1508\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(pred_df, train_df, test_df, k=10, threshold=3.5):\n",
    "    precision_list = []\n",
    "    for user in test_df['user_id'].unique():\n",
    "        if user not in pred_df.index:\n",
    "            continue\n",
    "        user_rated_movies = set(train_df[train_df['user_id'] == user]['movie_id'])\n",
    "        user_test = test_df[test_df['user_id'] == user]\n",
    "        user_preds = pred_df.loc[user].drop(labels=user_rated_movies, errors='ignore')\n",
    "        top_k_preds = user_preds.sort_values(ascending=False).head(k)\n",
    "        \n",
    "        relevant = set(user_test[user_test['user_rating'] >= threshold]['movie_id'])\n",
    "        recommended = set(top_k_preds.index)\n",
    "        hits = len(recommended & relevant)\n",
    "        precision = hits / k\n",
    "        precision_list.append(precision)\n",
    "    return np.mean(precision_list)\n",
    "\n",
    "print(f\"SVD Precision@10: {precision_at_k(predicted_svd_df, train_data, test_data):.4f}\")\n",
    "print(f\"NMF Precision@10: {precision_at_k(predicted_nmf_df, train_data, test_data):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eeb77ad-d427-4eef-a3db-18f1346440f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Summary:\n",
      "           Model  RMSE  Precision@10\n",
      "0  User-Based CF  0.96          0.21\n",
      "1  Item-Based CF  0.94          0.23\n",
      "2            SVD  0.91          0.26\n",
      "3  Content-Based   NaN          0.18\n"
     ]
    }
   ],
   "source": [
    "# Week 3 & 4: Content-Based, Hybrid Recommender, Evaluation Table, Streamlit UI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# --- Content-Based Filtering ---\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['clean_movie_title'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "title_to_index = pd.Series(movies.index, index=movies['clean_movie_title'].str.lower())\n",
    "\n",
    "def get_content_recommendations(title, n=10):\n",
    "    title = title.lower()\n",
    "    if title not in title_to_index:\n",
    "        return pd.DataFrame(columns=[\"movie_id\", \"movie_title\"])\n",
    "    idx = title_to_index[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies[['movie_id', 'movie_title']].iloc[movie_indices].reset_index(drop=True)\n",
    "\n",
    "# --- Collaborative Filtering with SVD ---\n",
    "user_item_matrix = ratings.pivot_table(index='user_id', columns='movie_id', values='user_rating').fillna(0)\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "user_features = svd.fit_transform(user_item_matrix)\n",
    "item_features = svd.components_\n",
    "predicted_ratings = np.dot(user_features, item_features)\n",
    "predicted_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "def recommend_svd(user_id, predicted_df, movies_df, user_item_df, n=5):\n",
    "    if user_id not in predicted_df.index:\n",
    "        return pd.DataFrame(columns=[\"movie_id\", \"movie_title\"])\n",
    "    user_row = predicted_df.loc[user_id]\n",
    "    user_row = user_row[~(user_item_df.loc[user_id] > 0)]\n",
    "    top_ids = user_row.nlargest(n).index\n",
    "    recs = movies_df[movies_df['movie_id'].isin(top_ids)][['movie_id', 'movie_title']]\n",
    "    return recs.set_index('movie_id').loc[top_ids].reset_index()\n",
    "\n",
    "# --- Hybrid Recommender (SVD + Content Intersection) ---\n",
    "def hybrid_recommend(user_id, predicted_df, movies_df, user_item_df, tfidf_sim=cosine_sim, n=5):\n",
    "    if user_id not in predicted_df.index:\n",
    "        return pd.DataFrame(columns=[\"movie_id\", \"movie_title\"])\n",
    "    user_row = predicted_df.loc[user_id]\n",
    "    unrated = user_row[~(user_item_df.loc[user_id] > 0)]\n",
    "    top_svd_ids = unrated.nlargest(30).index  # wider pool\n",
    "    movie_idxs = movies[movies['movie_id'].isin(top_svd_ids)].index\n",
    "    sim_avg = cosine_sim[movie_idxs].mean(axis=1)\n",
    "    top_idx = sim_avg.argsort()[::-1][:n]\n",
    "    movie_ids = movies.iloc[movie_idxs[top_idx]]['movie_id']\n",
    "    return movies[movies['movie_id'].isin(movie_ids)][['movie_id', 'movie_title']].reset_index(drop=True)\n",
    "\n",
    "# --- Evaluation Table Example (dummy values) ---\n",
    "evaluation_results = pd.DataFrame({\n",
    "    'Model': ['User-Based CF', 'Item-Based CF', 'SVD', 'Content-Based'],\n",
    "    'RMSE': [0.96, 0.94, 0.91, None],\n",
    "    'Precision@10': [0.21, 0.23, 0.26, 0.18]\n",
    "})\n",
    "print(\"\\nModel Evaluation Summary:\")\n",
    "print(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc273db-3860-469f-9301-c41e45a6f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
